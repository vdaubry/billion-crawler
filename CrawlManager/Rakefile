require_relative 'billion_crawler'
require 'bundler'
 
namespace :debug do
  
  QUEUE_NAME = "new_urls"
  
  desc 'Add seed urls'
  task :seed do
    puts "Empty Redis..."
    $redis.flushall

    urls = ["http://www.google.com", "http://www.wikipedia.org/"]
    frontier = Crawler::UrlFrontier.new
    urls.each do |url|
      puts "Add #{url} to queue"
      Crawler::ScrapperDomain.new(host: URI.parse(url).host).add_url(url: url)
      frontier.add(url: url, parent_url: nil, current_depth: 0)
    end
  end

  desc 'Add an URL from param to the frontier '
  task :crawl_url, :url do |t, args|
    puts "Empty Redis..."
    $redis.flushall
    
    url = args[:url]
    puts "Add #{url} to queue"
    Crawler::ScrapperDomain.new(host: URI.parse(url).host).add_url(url: url)
    frontier.add(url: url, parent_url: nil, current_depth: 0)
  end
end

namespace :rules do
  desc "load domain blacklist and whitelist urls"
  task :load do
    puts "Loads rules from config/rules.yml"
    Rules::Parser.new.read
  end
end